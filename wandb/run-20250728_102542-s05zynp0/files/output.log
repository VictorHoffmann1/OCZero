[main process] Global storage server has been started from main process.
[main process] Batch storage has been initialized.
[main process] Replay buffer server has been started from main process.
[Watchdog Server] Watchdog server initialized.
[main process] Watchdog server has been started from main process.
[Data worker] Start data worker 0 at process 11897.
[main process] Data workers have all been launched.
[Batch worker GPU] Starting batch worker GPU 0 at process 11897.
[Batch worker GPU] Starting batch worker GPU 1 at process 11897.
[Batch worker GPU] Starting batch worker GPU 2 at process 11897.
[Batch worker GPU] Starting batch worker GPU 3 at process 11897.
[Batch worker GPU] Starting batch worker GPU 4 at process 11897.
[Batch worker GPU] Starting batch worker GPU 5 at process 11897.
[Batch worker GPU] Starting batch worker GPU 6 at process 11897.
[Batch worker GPU] Starting batch worker GPU 7 at process 11897.
[main process] Batch workers have all been launched.
[main process] torch version is 2.7.1+cu126, enabled torch_compile.
[2025-07-28 10:25:43,343][Train][INFO] - config: {'root_dir': '.', 'exp_config': 'components/config/exp/atari.yaml', 'tag': 'EZ-V2', 'debug': False, 'save_path': 'results/Atari/Breakout/EZ-V2-seed=0-2025-07-28 10:25:37/', 'agent_name': 'atari_agent', 'env': {'env': 'Atari', 'game': 'Breakout', 'base_seed': 0, 'n_skip': 4, 'n_stack': 1, 'max_episode_steps': 3000, 'clip_reward': True, 'max_objects': 32, 'use_color': False, 'obs_shape': [32, 6], 'episodic': True, 'action_space_size': 4}, 'rl': {'discount': 0.988053892081, 'unroll_steps': 5, 'td_steps': 5, 'auto_td_steps': 30000, 'td_lambda': 0.95}, 'optimizer': {'type': 'SGD', 'lr': 0.2, 'lr_decay_type': 'none', 'lr_warm_up': 0.01, 'lr_decay_rate': 0.1, 'lr_decay_steps': 100000, 'weight_decay': 0.0001, 'momentum': 0.9}, 'priority': {'use_priority': True, 'priority_prob_alpha': 1.0, 'priority_prob_beta': 1.0, 'min_prior': 1e-06}, 'train': {'load_model_path': '', 'batch_size': 256, 'training_steps': 100000, 'offline_training_steps': 20000, 'start_transitions': 2000, 'eval_n_episode': 10, 'eval_interval': 10000, 'self_play_update_interval': 100, 'reanalyze_update_interval': 200, 'save_ckpt_interval': 10000, 'mini_batch_size': 256, 'reanalyze_ratio': 1.0, 'reward_loss_coeff': 1.0, 'value_loss_coeff': 0.5, 'policy_loss_coeff': 1.0, 'consistency_coeff': 5.0, 'decorrelation_coeff': 0.01, 'off_diag_coeff': 0.005, 'entropy_coeff': 0.005, 'max_grad_norm': 5, 'change_temperature': True, 'periodic_reset': False, 'value_reanalyze': False, 'path_consistency': False, 'use_decorrelation': False, 'value_policy_detach': False, 'optimal_Q': False, 'v_num': 1, 'value_target': 'mixed', 'use_IQL': False, 'IQL_weight': 0.7, 'start_use_mix_training_steps': 30000.0, 'mixed_value_threshold': 5000.0}, 'data': {'num_envs': 4, 'buffer_size': 1000000, 'total_transitions': 100000, 'top_transitions': 200000.0, 'trajectory_size': 400, 'save_video': False, 'save_as_dataset': False}, 'mcts': {'language': 'cython', 'num_simulations': 16, 'num_top_actions': 4, 'c_visit': 50, 'c_scale': 0.1, 'c_base': 19652, 'c_init': 1.25, 'dirichlet_alpha': 0.3, 'explore_frac': 0.25, 'value_minmax_delta': 0.01, 'vis': ['print'], 'mpc_horizon': 1, 'use_gumbel': True}, 'model': {'hidden_dim': 64, 'top_k': 16, 'noisy_net': False, 'state_norm': False, 'value_prefix': True, 'value_target': 'bootstrapped', 'GAE_max_steps': 15, 'init_zero': True, 'projection_layers': [512, 512], 'prjection_head_layers': [128, 512], 'fc_layers': [32], 'lstm_hidden_size': 128, 'lstm_horizon_len': 5, 'policy_loss_type': 'reanalyze', 'reward_support': {'range': [-300, 300], 'scale': 1, 'env': 'Atari', 'bins': 51, 'type': 'support', 'size': 601}, 'value_support': {'range': [-300, 300], 'scale': 1, 'env': 'Atari', 'bins': 51, 'type': 'support', 'size': 601}}, 'actors': {'data_worker': 1, 'batch_worker': 8}, 'wandb': {'project': 'OCZero', 'tag': 'Atari'}, 'augmentation': None, 'ddp': {'world_size': 1, 'training_size': 1, 'address': '127.0.0.1'}, 'ray': {'single_process': False}, 'log': {'log_interval': 100, 'log_smos': False}, 'eval': {'verbose': 0, 'save_path': 'test', 'model_path': 'results/Atari/Breakout/EZ-V2-seed=0-2023-08-10 00:40:53/models/model_10000.p', 'model_path_new': 'results/Atari/Breakout/EZ-V2-seed=0-2023-08-10 00:40:53/models/model_80000.p', 'n_episodes': 10, 'compare_value': False, 'analysis_value': False}}
[2025-07-28 10:25:43,345][Train][INFO] - save model in: results/Atari/Breakout/EZ-V2-seed=0-2025-07-28 10:25:37/models
[36m(BatchWorker pid=12298)[39m Exception raised in creation task: The actor died because of an error raised in its creation task, [36mray::BatchWorker.__init__()[39m (pid=12298, ip=172.24.247.44, actor_id=28064631d726e53ec7f7747d01000000, repr=<components.worker.batch_worker.BatchWorker object at 0x7fba5b1c4790>)
[36m(BatchWorker pid=12298)[39m   File "/home/victo/projects/EfficientZeroV2/components/worker/batch_worker.py", line 58, in __init__
[36m(BatchWorker pid=12298)[39m     self.gray_scale = self.config.env.gray_scale
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/dictconfig.py", line 359, in __getattr__
[36m(BatchWorker pid=12298)[39m     self._format_and_raise(key=key, value=None, cause=e)
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/base.py", line 231, in _format_and_raise
[36m(BatchWorker pid=12298)[39m     format_and_raise(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/_utils.py", line 819, in format_and_raise
[36m(BatchWorker pid=12298)[39m     _raise(ex, cause)
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/_utils.py", line 797, in _raise
[36m(BatchWorker pid=12298)[39m     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/dictconfig.py", line 351, in __getattr__
[36m(BatchWorker pid=12298)[39m     return self._get_impl(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/dictconfig.py", line 442, in _get_impl
[36m(BatchWorker pid=12298)[39m     node = self._get_child(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/basecontainer.py", line 73, in _get_child
[36m(BatchWorker pid=12298)[39m     child = self._get_node(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/dictconfig.py", line 475, in _get_node
[36m(BatchWorker pid=12298)[39m     self._validate_get(key)
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/dictconfig.py", line 164, in _validate_get
[36m(BatchWorker pid=12298)[39m     self._format_and_raise(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/base.py", line 231, in _format_and_raise
[36m(BatchWorker pid=12298)[39m     format_and_raise(
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/_utils.py", line 899, in format_and_raise
[36m(BatchWorker pid=12298)[39m     _raise(ex, cause)
[36m(BatchWorker pid=12298)[39m   File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/omegaconf/_utils.py", line 797, in _raise
[36m(BatchWorker pid=12298)[39m     raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace
[36m(BatchWorker pid=12298)[39m omegaconf.errors.ConfigAttributeError: Key 'gray_scale' is not in struct
[36m(BatchWorker pid=12298)[39m     full_key: env.gray_scale
[36m(BatchWorker pid=12298)[39m     object_type=dict
[36m(EvalWorker pid=12302)[39m [Eval] Start evaluation at step 0.
[36m(DataWorker pid=12292)[39m A.L.E: Arcade Learning Environment (version 0.11.1+2750686)
[36m(DataWorker pid=12292)[39m [Powered by Stella]
2025-07-28 10:25:49,858	ERROR worker.py:427 -- Unhandled error (suppress with 'RAY_IGNORE_UNHANDLED_ERRORS=1'): [36mray::EvalWorker.run()[39m (pid=12302, ip=172.24.247.44, actor_id=415bc5acb075019be432f8a601000000, repr=<components.worker.eval_worker.EvalWorker object at 0x7fa8fefe3d60>)
  File "/home/victo/projects/EfficientZeroV2/components/worker/eval_worker.py", line 46, in run
    eval_score = eval(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 116, in decorate_context
    return func(*args, **kwargs)
  File "/home/victo/projects/EfficientZeroV2/components/eval.py", line 95, in eval
    envs = make_envs(
  File "/home/victo/projects/EfficientZeroV2/components/environment/__init__.py", line 40, in make_envs
    envs = [
  File "/home/victo/projects/EfficientZeroV2/components/environment/__init__.py", line 41, in <listcomp>
    _env_fn(
  File "/home/victo/projects/EfficientZeroV2/components/environment/__init__.py", line 129, in make_atari
    env = Monitor(env, filename=save_path, override_existing=True)
  File "/home/victo/projects/EfficientZeroV2/components/environment/wrapper.py", line 278, in __init__
    self.results_writer = ResultsWriter(
  File "/home/victo/projects/EfficientZeroV2/components/environment/wrapper.py", line 417, in __init__
    if not filename.endswith(Monitor.EXT):
AttributeError: 'PosixPath' object has no attribute 'endswith'
Traceback (most recent call last):
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 164, in <module>
    main()
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 49, in main
    start_ddp_trainer(0, config)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 87, in start_ddp_trainer
    final_weights = train(rank, agent, manager, logger, config)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 111, in train
    final_weights, final_model = agent.train(
  File "/home/victo/projects/EfficientZeroV2/components/agents/base.py", line 163, in train
    time.sleep(1)
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 164, in <module>
    main()
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/main.py", line 94, in decorated_main
    _run_hydra(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 394, in _run_hydra
    _run_app(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 457, in _run_app
    run_and_report(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 220, in run_and_report
    return func()
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/utils.py", line 458, in <lambda>
    lambda: hydra.run(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/_internal/hydra.py", line 119, in run
    ret = run_job(
  File "/home/victo/.pyenv/versions/oc_atari_rl/lib/python3.9/site-packages/hydra/core/utils.py", line 186, in run_job
    ret.return_value = task_function(task_cfg)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 49, in main
    start_ddp_trainer(0, config)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 87, in start_ddp_trainer
    final_weights = train(rank, agent, manager, logger, config)
  File "/home/victo/projects/EfficientZeroV2/components/train.py", line 111, in train
    final_weights, final_model = agent.train(
  File "/home/victo/projects/EfficientZeroV2/components/agents/base.py", line 163, in train
    time.sleep(1)
KeyboardInterrupt