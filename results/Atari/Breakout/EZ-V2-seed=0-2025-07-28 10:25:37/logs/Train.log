[2025-07-28 10:25:43,343][Train][INFO][base.py>train] ==> config: {'root_dir': '.', 'exp_config': 'components/config/exp/atari.yaml', 'tag': 'EZ-V2', 'debug': False, 'save_path': 'results/Atari/Breakout/EZ-V2-seed=0-2025-07-28 10:25:37/', 'agent_name': 'atari_agent', 'env': {'env': 'Atari', 'game': 'Breakout', 'base_seed': 0, 'n_skip': 4, 'n_stack': 1, 'max_episode_steps': 3000, 'clip_reward': True, 'max_objects': 32, 'use_color': False, 'obs_shape': [32, 6], 'episodic': True, 'action_space_size': 4}, 'rl': {'discount': 0.988053892081, 'unroll_steps': 5, 'td_steps': 5, 'auto_td_steps': 30000, 'td_lambda': 0.95}, 'optimizer': {'type': 'SGD', 'lr': 0.2, 'lr_decay_type': 'none', 'lr_warm_up': 0.01, 'lr_decay_rate': 0.1, 'lr_decay_steps': 100000, 'weight_decay': 0.0001, 'momentum': 0.9}, 'priority': {'use_priority': True, 'priority_prob_alpha': 1.0, 'priority_prob_beta': 1.0, 'min_prior': 1e-06}, 'train': {'load_model_path': '', 'batch_size': 256, 'training_steps': 100000, 'offline_training_steps': 20000, 'start_transitions': 2000, 'eval_n_episode': 10, 'eval_interval': 10000, 'self_play_update_interval': 100, 'reanalyze_update_interval': 200, 'save_ckpt_interval': 10000, 'mini_batch_size': 256, 'reanalyze_ratio': 1.0, 'reward_loss_coeff': 1.0, 'value_loss_coeff': 0.5, 'policy_loss_coeff': 1.0, 'consistency_coeff': 5.0, 'decorrelation_coeff': 0.01, 'off_diag_coeff': 0.005, 'entropy_coeff': 0.005, 'max_grad_norm': 5, 'change_temperature': True, 'periodic_reset': False, 'value_reanalyze': False, 'path_consistency': False, 'use_decorrelation': False, 'value_policy_detach': False, 'optimal_Q': False, 'v_num': 1, 'value_target': 'mixed', 'use_IQL': False, 'IQL_weight': 0.7, 'start_use_mix_training_steps': 30000.0, 'mixed_value_threshold': 5000.0}, 'data': {'num_envs': 4, 'buffer_size': 1000000, 'total_transitions': 100000, 'top_transitions': 200000.0, 'trajectory_size': 400, 'save_video': False, 'save_as_dataset': False}, 'mcts': {'language': 'cython', 'num_simulations': 16, 'num_top_actions': 4, 'c_visit': 50, 'c_scale': 0.1, 'c_base': 19652, 'c_init': 1.25, 'dirichlet_alpha': 0.3, 'explore_frac': 0.25, 'value_minmax_delta': 0.01, 'vis': ['print'], 'mpc_horizon': 1, 'use_gumbel': True}, 'model': {'hidden_dim': 64, 'top_k': 16, 'noisy_net': False, 'state_norm': False, 'value_prefix': True, 'value_target': 'bootstrapped', 'GAE_max_steps': 15, 'init_zero': True, 'projection_layers': [512, 512], 'prjection_head_layers': [128, 512], 'fc_layers': [32], 'lstm_hidden_size': 128, 'lstm_horizon_len': 5, 'policy_loss_type': 'reanalyze', 'reward_support': {'range': [-300, 300], 'scale': 1, 'env': 'Atari', 'bins': 51, 'type': 'support', 'size': 601}, 'value_support': {'range': [-300, 300], 'scale': 1, 'env': 'Atari', 'bins': 51, 'type': 'support', 'size': 601}}, 'actors': {'data_worker': 1, 'batch_worker': 8}, 'wandb': {'project': 'OCZero', 'tag': 'Atari'}, 'augmentation': None, 'ddp': {'world_size': 1, 'training_size': 1, 'address': '127.0.0.1'}, 'ray': {'single_process': False}, 'log': {'log_interval': 100, 'log_smos': False}, 'eval': {'verbose': 0, 'save_path': 'test', 'model_path': 'results/Atari/Breakout/EZ-V2-seed=0-2023-08-10 00:40:53/models/model_10000.p', 'model_path_new': 'results/Atari/Breakout/EZ-V2-seed=0-2023-08-10 00:40:53/models/model_80000.p', 'n_episodes': 10, 'compare_value': False, 'analysis_value': False}}
[2025-07-28 10:25:43,345][Train][INFO][base.py>train] ==> save model in: results/Atari/Breakout/EZ-V2-seed=0-2025-07-28 10:25:37/models
